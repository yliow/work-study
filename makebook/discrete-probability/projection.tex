%-*-latex-*-
\sectionthree{Projection}
\begin{python0}
from solutions import *; clear()
\end{python0}

Somewhat similar is the case where you use random variables
as projection onto a coordinate for the case when the
sample space is a product of space spaces.
For instance consider the random experiment of
tossing a coin and rolling a die.
The sample space is
\[
S =
\{\HEAD, \TAIL \}
\times
\{\ONE, \TWO, ..., \SIX \}
\]
We can define the random variable $X$ to be
\[
X : S \rightarrow
\{\HEAD, \TAIL \}
\]
where
\[
X((x, y)) = x
\]
and $Y$ to be
\[
Y : S \rightarrow
\{\ONE, ..., \SIX \}
\]
where
\[
Y((x, y)) = y
\]

(\textsc{Aside}. Note that the outcomes look like $(x, y)$.
So the correct way to write the $X$ of $(x, y)$ is
$X((x, y))$.
But it's also common to write it as $X(x, y)$.)

This is like labelings.

To make things more readable, let me
define the random variable $\textsc{Toss}$
to be the same as $X$ and the random
variable $\textsc{Roll}$ to be the same
as the random variable $Y$.
The random variable $\textsc{Toss}$ labels
the outcome $(\HEAD, \TWO)$ as $\HEAD$ -- i.e., it
simply labels $(x, y)$ as $x$.


Now consider probabilities.
It should be clear that, assuming the coin and die are both fair
that the pdf is uniform:
\[
p((x, y)) = 1/12
\]
The probability
\[
\Pr[\operatorname{Toss} = \HEAD]
\]
is simply
\[
p( \{ (x,y) \in S \mid \operatorname{Toss}(x,y) = \HEAD \} )
\]
which is
\[
p(\{(\HEAD,y) \mid y \in \{\ONE, ..., \SIX\}\} )
\]
This is the probability of tossing a coin and rolling a die and the
coin toss happens to be  head.

\input{exercises/discrete-probability/disc-prob-11/main.tex}

The point of the above is that
\[
p_{\textsc{Toss}}(x) = \Pr[\textsc{Toss} = x]
\]
The left-hand side is about the sample space $\{\HEAD, \TAIL\}$
whereas on the right-hand side, the sample space is
$\{\HEAD, \TAIL\} \times \{ \ONE, \ldots, \SIX \}$.
